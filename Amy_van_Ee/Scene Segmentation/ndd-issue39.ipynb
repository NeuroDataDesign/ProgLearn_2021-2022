{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proglearn: Scene Segmentation\n",
    "*Neuro Data Design I: Fall 2021*\n",
    "\n",
    "\n",
    "This tutorial provides a walkthrough into applying Proglearn to perform scene segmentation on the ADE20K image dataset.\n",
    "\n",
    "\n",
    "**Contributors**\n",
    "- Kevin Rao (krao15@jhu.edu)\n",
    "- Amy van Ee (avanee1@jhu.edu)\n",
    "- Narayani Wagle (nwagle1@jhu.edu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Preprocessing of Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Other Methods of Scene Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II.A. Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test other methods of scene segmentation before implementation of Python, we will use scikit-image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize an Example Image**\n",
    "\n",
    "We will choose the image of a palm tree on a beach from the ADE20K dataset to confirm that this method works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================================#\n",
    "# Plot the original image alongside the annotated image\n",
    "\n",
    "fig, ax = plt.subplots(1,2)\n",
    "fig.set_size_inches(10,10)\n",
    "\n",
    "image = cv2.imread(imgpaths[9])\n",
    "label = cv2.imread(lblpaths[9]) \n",
    "ax[0].imshow(image)\n",
    "ax[0].set_title(\"Original Image\")\n",
    "\n",
    "ax[1].imshow(label)\n",
    "ax[1].set_title(\"True Annotations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================================#\n",
    "# Show a histogram of the image\n",
    "\n",
    "# tuple to select colors of each channel line\n",
    "colors = (\"red\", \"green\", \"blue\")\n",
    "channel_ids = (0, 1, 2)\n",
    "\n",
    "# create the histogram plot, with three lines, one for\n",
    "# each color\n",
    "plt.xlim([0, 256])\n",
    "for channel_id, c in zip(channel_ids, colors):\n",
    "    histogram, bin_edges = np.histogram(\n",
    "        label[:, :, channel_id], bins=256, range=(0, 256)\n",
    "    )\n",
    "    plt.plot(bin_edges[0:-1], histogram, color=c)\n",
    "\n",
    "plt.xlabel(\"Color Value\")\n",
    "plt.ylabel(\"Pixel Count\")\n",
    "plt.title(\"Histogram of Annotated Images in RGB: %d labels\" %(np.unique(label).size))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize the Greyscale of the Image**\n",
    "\n",
    "Although the annotated image from the ADE20K dataset has three color channels (RGB) as just shown in the histogram, scikit-image produces an annotated image that has only one. Therefore, in using the provided functions in this package, we will convert to greyscale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================================#\n",
    "# Convert to greyscale\n",
    "\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "image_grey = rgb2gray(image)\n",
    "label_grey = rgb2gray(label)\n",
    "label_grey = label_grey * 1000\n",
    "label_grey = label_grey.astype(int)\n",
    "\n",
    "fig, ax = plt.subplots(1,2)\n",
    "fig.set_size_inches(10,10)\n",
    "\n",
    "ax[0].imshow(image_grey, cmap = plt.cm.gray)\n",
    "ax[0].set_title(\"Original Image\")\n",
    "\n",
    "ax[1].imshow(label_grey, cmap = plt.cm.gray)\n",
    "ax[1].set_title(\"True Annotations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================================#\n",
    "# Show a histogram of the grey-scale image\n",
    "\n",
    "plt.hist(label_grey)\n",
    "plt.title(\"Histogram of Greyscale Annotated Image: %d Classes\" %(np.unique(label_grey).size))\n",
    "plt.xlabel(\"Intensity\")\n",
    "plt.ylabel(\"Pixel Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Performing the Image Segmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================================#\n",
    "# Use scikit-image to perform Image Segmentation\n",
    "\n",
    "from skimage import segmentation, feature, future\n",
    "from functools import partial\n",
    "\n",
    "img = image_grey\n",
    "training_labels = label_grey\n",
    "\n",
    "sigma_min = 1\n",
    "sigma_max = 16\n",
    "features_func = partial(feature.multiscale_basic_features,\n",
    "                        intensity=True, edges=False, texture=True,\n",
    "                        sigma_min=sigma_min, sigma_max=sigma_max,\n",
    "                        multichannel=True)\n",
    "features = features_func(img)\n",
    "clf = RandomForestClassifier(n_estimators=50, n_jobs=-1,\n",
    "                             max_depth=10, max_samples=0.05)\n",
    "clf = future.fit_segmenter(training_labels, features, clf)\n",
    "result = future.predict_segmenter(features, clf)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(9, 4))\n",
    "ax[0].imshow(segmentation.mark_boundaries(img, result, mode='thick'))\n",
    "ax[0].contour(training_labels)\n",
    "ax[0].set_title('Image, mask and segmentation boundaries')\n",
    "ax[1].imshow(result, cmap = plt.cm.gray)\n",
    "ax[1].set_title('Segmentation')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analyzing Accuracy**\n",
    "\n",
    "We will next analyze the performance of scikit-image by analyzing the accuracy. We will do so by comparing the outcome from scene segmentation and the true annotated image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================================#\n",
    "# Analyze the accuracy by looking at \n",
    "# precision, recall, false splits, false merges, dice score\n",
    "\n",
    "from skimage.metrics import (adapted_rand_error,\n",
    "                              variation_of_information)\n",
    "def get_dice(true, test):\n",
    "    return np.size(test[test == true]) * 2.0 / (np.size(true) + np.size(test))\n",
    "\n",
    "error, precision, recall = adapted_rand_error(label_grey, result)\n",
    "splits, merges = variation_of_information(label_grey, result)\n",
    "dice = get_dice(label_grey, result)\n",
    "print(f'Adapted Rand error: {error}')\n",
    "print(f'Adapted Rand precision: {precision}')\n",
    "print(f'Adapted Rand recall: {recall}')\n",
    "print(f'False Splits: {splits}')\n",
    "print(f'False Merges: {merges}')\n",
    "prift(f'Dice Coefficient: {dice}')\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(6, 6), constrained_layout=True)\n",
    "ax = axes.ravel()\n",
    "\n",
    "ax[0].scatter(merges, splits)\n",
    "ax[0].set_xlabel('False Merges (bits)')\n",
    "ax[0].set_ylabel('False Splits (bits)')\n",
    "ax[0].set_title('Split Variation of Information')\n",
    "\n",
    "ax[1].scatter(precision, recall)\n",
    "ax[1].set_xlabel('Precision')\n",
    "ax[1].set_ylabel('Recall')\n",
    "ax[1].set_title('Adapted Random precision vs. recall')\n",
    "ax[1].set_xlim(0, 1)\n",
    "ax[1].set_ylim(0, 1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evidently, it appears that scikit-image did a relatively good job of scene segmentation. Thus, we proceed to apply it to a larger dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Performing Scene Segmentation on entire dataset**\n",
    "\n",
    "Next, we will try to perform scene segmentation on the entire dataset. However, it was found that the original images and annotated images did not have the same dimensionality, which was a requirement for scikit-image's functionality. Therefore, we selectively chose images whose original and annotated versions had the same dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================================#\n",
    "# convert all images to greyscale\n",
    "images_grey = np.array([rgb2gray(cv2.imread(imgpath)) for imgpath in imgpaths])\n",
    "labels_grey = np.array([(rgb2gray(cv2.imread(lblpath))*1000).astype(int) for lblpath in lblpaths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================================#\n",
    "# identify images with matching dimensions between image and label\n",
    "images_grey_match = images_grey[[images_grey[i].shape == labels_grey[i].shape for i in np.arange(len(images_grey))]]\n",
    "labels_grey_match = labels_grey[[images_grey[i].shape == labels_grey[i].shape for i in np.arange(len(images_grey))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================================#\n",
    "# perform scene segmentation on all images\n",
    "\n",
    "# initialize arrays\n",
    "error_list = np.zeros(len(images_grey_match))\n",
    "precision_list = np.zeros(len(images_grey_match))\n",
    "recall_list = np.zeros(len(images_grey_match))\n",
    "splits_list = np.zeros(len(images_grey_match))\n",
    "merges_list = np.zeros(len(images_grey_match))\n",
    "dice_list = np.zeros(len(images_grey_match))\n",
    "result_list = np.zeros(len(images_grey_match), dtype = object)\n",
    "\n",
    "# loop through each image and determine values\n",
    "for i in np.arange(len(images_grey_match)):\n",
    "    # use classifier\n",
    "    features = features_func(images_grey_match[i])\n",
    "    result = future.predict_segmenter(features, clf)\n",
    "\n",
    "    # assess\n",
    "    error, precision, recall = adapted_rand_error(labels_grey_match[i], result)\n",
    "    splits, merges = variation_of_information(labels_grey_match[i], result)\n",
    "    dice = get_dice(labels_grey_match[i], result)\n",
    "\n",
    "    # add to list\n",
    "    error_list[i] = error\n",
    "    precision_list[i] = precision\n",
    "    recall_list[i] = recall\n",
    "    splits_list[i] = splits\n",
    "    merges_list[i] = merges\n",
    "    dice_list[i] = dice\n",
    "    result_list[i] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================================#\n",
    "# analyze results\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(6, 6), constrained_layout=True)\n",
    "ax = axes.ravel()\n",
    "\n",
    "ax[0].scatter(merges_list, splits_list)\n",
    "ax[0].set_xlabel('False Merges (bits)')\n",
    "ax[0].set_ylabel('False Splits (bits)')\n",
    "ax[0].set_title('Split Variation of Information')\n",
    "\n",
    "ax[1].scatter(precision_list, recall_list)\n",
    "ax[1].set_xlabel('Precision')\n",
    "ax[1].set_ylabel('Recall')\n",
    "ax[1].set_title('Adapted Random precision vs. recall')\n",
    "ax[1].set_xlim(0, 1)\n",
    "ax[1].set_ylim(0, 1)\n",
    "\n",
    "ax[2].hist(dice_list)\n",
    "ax[2].set_xlabel('Dice Coefficient')\n",
    "ax[2].set_ylabel('Frequency')\n",
    "ax[2].set_title('Histogram of Dice Coefficients')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evidently, it appears that scikit-image is only able to fit to one specific image at a time, and therefore only the image with the palm tree had high accuracy values, whereas the other images did not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Looking at a Poorly Segmented Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================================#\n",
    "# see low accuracy since had only trained on one image which has high dice coefficient\n",
    "\n",
    "# original\n",
    "fig, ax = plt.subplots(1,2)\n",
    "fig.set_size_inches(10,10)\n",
    "\n",
    "ax[0].imshow(images_grey_match[1], cmap = plt.cm.gray)\n",
    "ax[0].set_title(\"Original Image\")\n",
    "\n",
    "ax[1].imshow(labels_grey_match[1], cmap = plt.cm.gray)\n",
    "ax[1].set_title(\"True Annotations\")\n",
    "plt.show()\n",
    "\n",
    "# segmented\n",
    "fig, ax = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(9, 4))\n",
    "ax[0].imshow(segmentation.mark_boundaries(images_grey_match[1], result_list[1], mode='thick'))\n",
    "ax[0].contour(labels_grey_match[1])\n",
    "ax[0].set_title('Image, mask and segmentation boundaries')\n",
    "ax[1].imshow(result_list[1], cmap = plt.cm.gray)\n",
    "ax[1].set_title('Segmentation')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This thus presents an opportunity for Proglearn to allow for improved and more generalizable scene segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II.B. Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Proglearn for Scene Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III.A. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next proceed to use the model of scikit-image to apply Proglearn for scene segmentation. We will use the LifelongClassificationForest in place of the RandomForestClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================================#\n",
    "# perform a basic test using one task\n",
    "\n",
    "from proglearn import LifelongClassificationForest\n",
    "\n",
    "# define forest\n",
    "progtree = LifelongClassificationForest()\n",
    "progtree.add_task(images_grey_match[9], labels_grey_match[9])\n",
    "\n",
    "# test prediction on a sample image\n",
    "prediction = progtree.predict(images_grey_match[10], task_id = 0)\n",
    "prediction_proba = progtree.predict_proba(images_grey_match[10], task_id = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, in doing so we come across the error of dimensionality. Proglearn as it is implemented now only takes in a 1D array for the class label, whereas the dataset ADE20K consists of labels per pixel. Therefore, more work will need to be done to accommodate this specific dataset. An alternative approach will be to use another dataset where the labels are binary and therefore the problem is more simplified before we scale up to a more complex situation like the ADE20K dataset. \n",
    "\n",
    "Ultimately, we hope to be able to use Proglearn and test our scene segmentation implementation using more than one task. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III.B. Neural Networks"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d9367bcf86695a30d1acceda906497f9af52eb4fe77482025fdfbf37cb0a7110"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
