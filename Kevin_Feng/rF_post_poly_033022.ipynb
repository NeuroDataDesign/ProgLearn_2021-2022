{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70ed724a-ebaf-47cf-ab85-84dd4b91463c",
   "metadata": {},
   "source": [
    "# Pseudocode\n",
    "3/28/22\n",
    "Generate the following:\n",
    "1. Train xor\n",
    "2. Test xor\n",
    "3. rxor 45 degrees\n",
    "\n",
    "Traing RF on train xor\n",
    "\n",
    "Push train xor (troubleshooting), test xor, test rxor through the RF using .apply() -> now we have arrays with leaf nodes that each sample ends up in\n",
    "\n",
    "Predict on test xor and rxor to get class labels for each sample -> array with 0's and 1's (y_pred_[r]xor)\n",
    "\n",
    "For test xor and rxor:\n",
    "    Get and iterate through unique polytopes (leaf nodes) -> get their idx's -> use y_pred_[r]xor[idx] to count number of 0's and 1's at each unique polytope\n",
    "    \n",
    "Might need to concat all unique idx's in xor and rxor sinec some only appear in one so we'd want the following dict to contain the polyope anyway ie [23: 0, 0] (example if xor didnt have poly 23 but rxor did)\n",
    "\n",
    "### Next steps:\n",
    "Instead of printing, store these counts of 0's and 1's in a dictionary with key = polytope and values = [# of 0's, # of 1's]\n",
    "\n",
    "For xor and rxor seperately, calculate % of samples at each polytope the belong to each label ie. [5: 10, 10] -> [5: 0.5, 0.5]\n",
    "\n",
    "Calculate l2 distance for each polytope between xor and rxor with above dictionary containing key = polytope, values = [%samples this polytope label0, [%samples this polytope label1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26cf6a8c-a2dd-4148-8c13-0443fddfadc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import \n",
    "import numpy as np\n",
    "import random\n",
    "from proglearn.sims import generate_gaussian_parity\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy as sc\n",
    "import sklearn.ensemble\n",
    "from sklearn import metrics \n",
    "import math\n",
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "696990d8-d2df-4f8d-969d-2f187449463f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of samples\n",
    "n_samples = 100\n",
    "\n",
    "# generate xor \n",
    "X_train, y_train = generate_gaussian_parity(n_samples, angle_params=0)\n",
    "# X_test, y_test = generate_gaussian_parity(100, angle_params=0)\n",
    "\n",
    "# generate rxor, 45 degrees\n",
    "X_test_rxor, y_test_rxor = generate_gaussian_parity(n_samples, angle_params=np.pi/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7784678d-eb17-4f47-9ebb-d0f9274ff2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = sklearn.ensemble.RandomForestClassifier(n_estimators=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "040f033a-9d9d-4aa0-8fb8-1b3b3f2d0d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=1)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model using the train data \n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# # predict using the test data\n",
    "# y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bf31d6e8-83d5-4bb9-b13c-43d66e0b8c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index of each array that each sample ends up in\n",
    "xor_leaves = clf.apply(X_train)\n",
    "rxor_leaves = clf.apply(X_test_rxor)\n",
    "# train_leaves = clf.apply(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4e5f2f47-207f-439e-a957-6885010ef85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted test xor labels\n",
    "y_pred_xor = clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "08e9f89b-195d-4d27-ab51-900169d95c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted rxor labels\n",
    "y_pred_rxor = clf.predict(X_test_rxor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b435583a-16b9-48fc-a797-c1eca79b5a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node 4 : 0 18\n",
      "node 5 : 8 0\n",
      "node 6 : 2 8\n",
      "node 9 : 21 0\n",
      "node 11 : 0 1\n",
      "node 12 : 3 0\n",
      "node 13 : 0 9\n",
      "node 15 : 8 5\n",
      "node 17 : 12 0\n",
      "node 18 : 0 5\n"
     ]
    }
   ],
   "source": [
    "for uni in np.unique(xor_leaves):\n",
    "    # idx of each unique polytope \n",
    "    poly_to_test = np.where(xor_leaves == uni)[0]\n",
    "    num_0 = 0\n",
    "    num_1 = 0\n",
    "\n",
    "    for i in poly_to_test:\n",
    "        if y_train[i] == 0: \n",
    "            num_0+=1\n",
    "        else:\n",
    "            num_1+=1\n",
    "            \n",
    "    print('node', uni, ':', num_0, num_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "10d1ede5-570d-4e8e-aee2-1e3cbe15b1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node 4 : 11 2\n",
      "node 5 : 5 0\n",
      "node 6 : 2 19\n",
      "node 9 : 9 8\n",
      "node 11 : 2 1\n",
      "node 12 : 10 0\n",
      "node 13 : 3 0\n",
      "node 15 : 3 6\n",
      "node 17 : 0 12\n",
      "node 18 : 0 7\n"
     ]
    }
   ],
   "source": [
    "for uni in np.unique(rxor_leaves):\n",
    "    # idx of each unique polytope\n",
    "    poly_to_test = np.where(rxor_leaves == uni)[0]\n",
    "    num_0 = 0\n",
    "    num_1 = 0\n",
    "\n",
    "    for i in poly_to_test:\n",
    "        if y_test_rxor[i] == 0: \n",
    "            num_0+=1\n",
    "        else:\n",
    "            num_1+=1\n",
    "            \n",
    "    print('node', uni, ':', num_0, num_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "46cb47ab-a0de-46fa-a458-484b4bbe17c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  5,  6,  9, 11, 12, 13, 15, 17, 18], dtype=int64)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(xor_leaves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d5672547-e1f2-4944-8a9f-ecd8fdaa8233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  5,  6,  9, 11, 12, 13, 15, 17, 18], dtype=int64)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(rxor_leaves)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a915b5b-df81-429c-888e-6bec31f127fa",
   "metadata": {},
   "source": [
    "## Next we need to modify our functions so that they return %'s, then use them to calc L2 distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a5a68e2e-beb7-4c93-bd12-87ade4fba16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_labels_at_poly_xor = {}\n",
    "for uni in np.unique(xor_leaves):\n",
    "    # idx of each unique polytope \n",
    "    poly_to_test = np.where(xor_leaves == uni)[0]\n",
    "    num_0 = 0\n",
    "    num_1 = 0\n",
    "    \n",
    "    # sum the number of each label at each poly/leaf\n",
    "    for i in poly_to_test:\n",
    "        if y_train[i] == 0: \n",
    "            num_0+=1\n",
    "        else:\n",
    "            num_1+=1\n",
    "            \n",
    "    # calc % of each label at each polytope/leaf\n",
    "    total_samples_at_poly = num_0 + num_1\n",
    "    perc_0 = num_0 / total_samples_at_poly\n",
    "    perc_1 = num_1 / total_samples_at_poly\n",
    "    \n",
    "    perc_labels_at_poly_xor[uni] = [perc_0, perc_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9b8f2329-f661-46df-9d3e-30d7ed96dc46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4: [0.0, 1.0],\n",
       " 5: [1.0, 0.0],\n",
       " 6: [0.2, 0.8],\n",
       " 9: [1.0, 0.0],\n",
       " 11: [0.0, 1.0],\n",
       " 12: [1.0, 0.0],\n",
       " 13: [0.0, 1.0],\n",
       " 15: [0.6153846153846154, 0.38461538461538464],\n",
       " 17: [1.0, 0.0],\n",
       " 18: [0.0, 1.0]}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perc_labels_at_poly_xor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "19c66fd5-4c35-4942-88ef-aa9fa34e93e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_labels_at_poly_rxor = {}\n",
    "for uni in np.unique(rxor_leaves):\n",
    "    # idx of each unique polytope \n",
    "    poly_to_test = np.where(rxor_leaves == uni)[0]\n",
    "    num_0 = 0\n",
    "    num_1 = 0\n",
    "    \n",
    "    # sum the number of each label at each poly/leaf\n",
    "    for i in poly_to_test:\n",
    "        if y_test_rxor[i] == 0: \n",
    "            num_0+=1\n",
    "        else:\n",
    "            num_1+=1\n",
    "            \n",
    "    # calc % of each label at each polytope/leaf\n",
    "    total_samples_at_poly = num_0 + num_1\n",
    "    perc_0 = num_0 / total_samples_at_poly\n",
    "    perc_1 = num_1 / total_samples_at_poly\n",
    "    \n",
    "    perc_labels_at_poly_rxor[uni] = [perc_0, perc_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c7b9ee80-4978-4e77-853e-92180c75c374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4: [0.8461538461538461, 0.15384615384615385],\n",
       " 5: [1.0, 0.0],\n",
       " 6: [0.09523809523809523, 0.9047619047619048],\n",
       " 9: [0.5294117647058824, 0.47058823529411764],\n",
       " 11: [0.6666666666666666, 0.3333333333333333],\n",
       " 12: [1.0, 0.0],\n",
       " 13: [1.0, 0.0],\n",
       " 15: [0.3333333333333333, 0.6666666666666666],\n",
       " 17: [0.0, 1.0],\n",
       " 18: [0.0, 1.0]}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perc_labels_at_poly_rxor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "73b9bc5e-e5a4-4ae9-905e-7624cd32e71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to do above but with any input (xor or rxor)\n",
    "def percentLabels(leaves, true_labels):\n",
    "    # dict to hold the %'s \n",
    "    # polytope as key, value = [% samples at this polytope with label 0, % samples at this polytope with label 1]\n",
    "    perc_labels_at_poly = {}\n",
    "    \n",
    "    for uni in np.unique(leaves):\n",
    "        # idx of each unique polytope \n",
    "        poly_to_test = np.where(leaves == uni)[0]\n",
    "        num_0 = 0\n",
    "        num_1 = 0\n",
    "\n",
    "        # sum the number of each label at each poly/leaf\n",
    "        for i in poly_to_test:\n",
    "            if true_labels[i] == 0: \n",
    "                num_0+=1\n",
    "            else:\n",
    "                num_1+=1\n",
    "\n",
    "        # calc % of each label at each polytope/leaf\n",
    "        total_samples_at_poly = num_0 + num_1\n",
    "        perc_0 = num_0 / total_samples_at_poly\n",
    "        perc_1 = num_1 / total_samples_at_poly\n",
    "\n",
    "        perc_labels_at_poly[uni] = [perc_0, perc_1]\n",
    "        \n",
    "    return perc_labels_at_poly\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "beb5f19a-96aa-4bca-b8a9-cfd3bc1b6606",
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_labels_at_poly_xor_2 = percentLabels(xor_leaves, y_train)\n",
    "perc_labels_at_poly_rxor_2 = percentLabels(rxor_leaves, y_test_rxor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "76ab8301-34e2-4244-83aa-dfcc55914159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure the function is working correctly \n",
    "perc_labels_at_poly_xor_2 == perc_labels_at_poly_xor, perc_labels_at_poly_rxor_2 == perc_labels_at_poly_rxor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7df77efe-6419-443b-b76d-9029647a0bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1966422450849266"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# l2 distance\n",
    "from scipy.spatial import distance\n",
    "distance.euclidean(perc_labels_at_poly_xor[4], perc_labels_at_poly_rxor[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e344f270-b3f3-4881-966b-940fb40f2ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate l2 distance between each rxor and xor polytope\n",
    "def l2_polytopes(xor_dict, rxor_dict):\n",
    "    # polytopes as keys, l2 distances as value\n",
    "    l2_poly_dict = {}\n",
    "    \n",
    "    # calc euc distance between each poly and store them in our dict\n",
    "    for key in xor_dict.keys():\n",
    "        l2_poly_dict[key] = distance.euclidean(xor_dict[key], rxor_dict[key])\n",
    "        \n",
    "    return l2_poly_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d741590f-0144-43c5-a665-0a918081359e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4: 1.1966422450849266,\n",
       " 5: 0.0,\n",
       " 6: 0.14815570653432422,\n",
       " 9: 0.6655122646461624,\n",
       " 11: 0.9428090415820634,\n",
       " 12: 0.0,\n",
       " 13: 1.4142135623730951,\n",
       " 15: 0.39888074836164217,\n",
       " 17: 1.4142135623730951,\n",
       " 18: 0.0}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_dists = l2_polytopes(perc_labels_at_poly_xor_2, perc_labels_at_poly_rxor_2)\n",
    "l2_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d406fc-5d70-4aa1-9c77-2e60ad75e2ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
