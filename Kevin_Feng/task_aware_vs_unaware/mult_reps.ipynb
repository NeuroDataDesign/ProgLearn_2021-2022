{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b6d9a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from proglearn.sims import generate_gaussian_parity\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# k sample testing from hyppo\n",
    "from hyppo.ksample import KSample\n",
    "from hyppo.tools import rot_ksamp\n",
    "\n",
    "from proglearn.forest import LifelongClassificationForest, UncertaintyForest\n",
    "from proglearn.sims import *\n",
    "from proglearn.progressive_learner import ProgressiveLearner\n",
    "from proglearn.deciders import SimpleArgmaxAverage\n",
    "from proglearn.transformers import (\n",
    "    TreeClassificationTransformer,\n",
    "    NeuralClassificationTransformer\n",
    ")\n",
    "from proglearn.voters import TreeClassificationVoter, KNNClassificationVoter\n",
    "from math import log2, ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6573d884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples to use per distribution\n",
    "n_samples = 1000\n",
    "# define number of estimators to use\n",
    "n_trees = 10\n",
    "# angles to pass to rxor\n",
    "angle_sweep = range(0, 95, 5)\n",
    "# num reps\n",
    "mc_reps = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d81cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### task unaware #####\n",
    "\n",
    "# arrays to store gen error\n",
    "pl_ge = np.zeros([mc_reps,19])\n",
    "pl_ge_t0 = np.zeros([mc_reps,19])\n",
    "uf1_ge = np.zeros([mc_reps,19])\n",
    "\n",
    "for i in range(mc_reps):\n",
    "    # dictionary to store task_id's for multiple reps\n",
    "    mult_rep_id_dict = {}\n",
    "    # generate task xor\n",
    "    X_xor, y_xor = generate_gaussian_parity(n_samples)\n",
    "    # generate test data\n",
    "    X_xor_test, y_xor_test = generate_gaussian_parity(n_samples)\n",
    "    # add xor data to dici,t\n",
    "    mult_rep_id_dict[0] = X_xor, y_xor\n",
    "    # testing with multiple runs\n",
    "    for rep, angle in enumerate(angle_sweep):\n",
    "        X_rxor, y_rxor = generate_gaussian_parity(n_samples, angle_params=np.radians(angle))\n",
    "        # train single run of model\n",
    "        progressive_learner = LifelongClassificationForest(default_n_estimators=n_trees)\n",
    "        # add xor data\n",
    "        progressive_learner.add_task(\n",
    "            mult_rep_id_dict[rep][0], mult_rep_id_dict[rep][1], n_estimators=n_trees\n",
    "        )\n",
    "        # init second LifeLongClassificationForest\n",
    "        uf1 = LifelongClassificationForest(default_n_estimators=n_trees)\n",
    "\n",
    "        # k sample test, add new task rxor and learn new transformer if p <= 0.05\n",
    "        if KSample(indep_test=\"Dcorr\").test(mult_rep_id_dict[rep][0], X_rxor)[1] <= 0.05:\n",
    "            progressive_learner.add_task(X_rxor, y_rxor, n_estimators=n_trees)\n",
    "            progressive_learner.add_transformer(X_rxor, y_rxor, n_estimators=n_trees)\n",
    "            uf1.add_task(X_rxor, y_rxor, n_estimators=2 * n_trees)\n",
    "\n",
    "            # calc errors\n",
    "\n",
    "            pl_ge[i,rep] = 1 - np.mean(\n",
    "                progressive_learner.predict(X_xor_test, task_id=1) == y_xor_test\n",
    "            )\n",
    "            pl_ge_t0[i,rep] = 1 - np.mean(\n",
    "                progressive_learner.predict(X_xor_test, task_id=0) == y_xor_test\n",
    "            )\n",
    "            uf1_ge[i,rep] = 1 - np.mean(uf1.predict(X_xor_test, task_id=0) == y_xor_test)\n",
    "\n",
    "            # X_xor_rxor = np.concatenate((mult_rep_id_dict[rep][0], X_rxor), axis=0)\n",
    "            # y_xor_rxor = np.concatenate((mult_rep_id_dict[rep][1], y_rxor), axis=0)\n",
    "            # mult_rep_id_dict[rep + 1] = X_xor_rxor, y_xor_rxor\n",
    "            # pass previous concatted data since we learned a new task\n",
    "            mult_rep_id_dict[rep + 1] = mult_rep_id_dict[rep]\n",
    "\n",
    "        else:\n",
    "            # else add concatenated xor and rxor data\n",
    "            X_xor_rxor = np.concatenate((mult_rep_id_dict[rep][0], X_rxor), axis=0)\n",
    "            y_xor_rxor = np.concatenate((mult_rep_id_dict[rep][1], y_rxor), axis=0)\n",
    "            progressive_learner.add_task(X_xor_rxor, y_xor_rxor, n_estimators=n_trees)\n",
    "            uf1.add_task(X_xor_rxor, y_xor_rxor, n_estimators=2 * n_trees)\n",
    "            mult_rep_id_dict[rep + 1] = X_xor_rxor, y_xor_rxor\n",
    "\n",
    "            # calc gen erros\n",
    "            pl_ge[i,rep] = 1 - np.mean(\n",
    "                progressive_learner.predict(X_xor_test, task_id=1) == y_xor_test\n",
    "            )\n",
    "            pl_ge_t0[i,rep] = 1 - np.mean(\n",
    "                progressive_learner.predict(X_xor_test, task_id=0) == y_xor_test\n",
    "            )\n",
    "            uf1_ge[i,rep] = 1 - np.mean(uf1.predict(X_xor_test, task_id=0) == y_xor_test)\n",
    "\n",
    "        # print(progressive_learner.get_task_ids(), uf1.get_task_ids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1456f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, (ax1, ax2, ax3) = plt.subplots(3)\n",
    "fig, (ax1, ax2) = plt.subplots(2)\n",
    "ax1.plot(angle_sweep, np.mean(pl_ge,axis=0))  # task_id = 1\n",
    "ax1.set_title(\"task_id = 1\")\n",
    "ax1.set_ylabel(\"Generalization Error\")\n",
    "ax2.plot(angle_sweep, np.mean(pl_ge_t0,axis=0))  # task_id = 0\n",
    "ax2.set_title(\"task_id = 0\")\n",
    "ax2.set_xlabel(\"Angle\")\n",
    "ax2.set_ylabel(\"Generalization Error\")\n",
    "fig.tight_layout()\n",
    "fig.savefig('task_unaware_gen_error_100reps.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0a9a7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
